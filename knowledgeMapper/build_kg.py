# build_kg.py

import asyncio
from lightrag import LightRAG
from local_models import HFEmbedFunc, OllamaLLM
from file_loader import load_documents


async def main():
    print("ğŸ“¥ Loading documents from ./data...")
    documents = load_documents("./data/ChatbotStuff")
    print(f"ğŸ” {len(documents)} documents loaded.")

    print("âš™ï¸ Initializing LightRAG with local LLM + Embeddings...")
    rag = LightRAG(
        working_dir="./rag_storage",
        embedding_func=HFEmbedFunc(),
        llm_model_func=OllamaLLM()
    )
    await rag.initialize_storages()

    print("ğŸ§  Building Knowledge Graph from documents...")
    await rag.apipeline_enqueue_documents(documents)
    await rag.apipeline_process_enqueue_documents()

    print("âœ… Knowledge graph + vector index saved to ./rag_storage")


asyncio.run(main())
