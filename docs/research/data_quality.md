# DatenqualitÃ¤t

Um den Fortschritt und die DatenqualitÃ¤t des Scrapers zu bestimmen, hier verschiedene Kategorien an denen man die QualitÃ¤t der Daten zwischen den verschiedenen Runs/Versionen beurteilen kann.

## ğŸ“ Allgemeine Ãœbersicht
- Anzahl der EintrÃ¤ge insgesamt
- Anzahl einzigartiger URLs
- Anzahl pro `type`: html, pdf, ical
- Neue vs. entfernte URLs zwischen zwei Runs

## ğŸ§¹ TextqualitÃ¤t
- Durchschnittliche TextlÃ¤nge (Zeichen oder WÃ¶rter)
- Median und maximale TextlÃ¤nge
- Anzahl leerer oder sehr kurzer Texte (z.â€¯B. < 20 Zeichen)
- Duplikate im Textinhalt (gleiche Texte bei verschiedenen URLs)

## ğŸ·ï¸ MetadatenqualitÃ¤t
- Anteil der EintrÃ¤ge mit leerem oder fehlendem `title`
- Anteil der EintrÃ¤ge mit fehlendem `date_updated`
- Anteil der EintrÃ¤ge mit gÃ¼ltigem `date_updated`-Format (ISO 8601)

## ğŸ” VerÃ¤nderungen im Vergleich
- Mehr oder weniger gefundene Seiten?
- Hat sich die TextlÃ¤nge verbessert (lÃ¤nger = oft besser)?
- Hat sich die Anzahl erkannter Datumsfelder verbessert?
- Gibt es neue Duplikate oder wurden welche entfernt?

# âœ… Nutzung

```bash
# Einzelnen Run analysieren
python3 compare_scraping_result.py run.json

# Zwei Runs vergleichen
python3 compare_scraping_result.py run1.json run2.json

# Mit Ã„nderungsanzeige (kompakt)
python3 compare_scraping_result.py run1.json run2.json -v

# Mit Ã„nderungsanzeige (detailliert)
python3 compare_scraping_result.py run1.json run2.json -vv
```